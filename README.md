# mlops-notes

![image](https://user-images.githubusercontent.com/11358728/118371768-6df4c380-b584-11eb-8f19-82edcf117c92.png)

> In contrast, I found that for a lot of product teams, if your main
goal is to just build and deploy a working valuable machine learning system,
I found that it can be even more effective to hold the code fixed and
to instead focus on optimizing the data and maybe the hyper parameters. 


> ...And I found that rather than taking a model centric view of trying to
optimize the code to your fixed data set for many problems,
you can use an open source implementation of something you download of GIT hub and
instead just focus on optimizing the data.
So during modeling, do you have to select and train some model architecture?
Maybe some neural network architecture error analysis can then tell
you where your model still falls short.
And if you can use that error analysis to tell you how to systematically
improve your data, maybe improve the code to that's okay.
But often if their analysis can tell you how to systematically improve the data,
that can be a very efficient way for you to get to a high accuracy model. 

![image](https://user-images.githubusercontent.com/11358728/118372273-38050e80-b587-11eb-9400-54b22ea1f81d.png)

Use recent data as test data to preemptively foresee productioin distribution mismatch.

![image](https://user-images.githubusercontent.com/11358728/118374268-756e9980-b591-11eb-815e-211c59a2b8a0.png)

![image](https://user-images.githubusercontent.com/11358728/118374337-e6ae4c80-b591-11eb-88bb-3c1c5c188499.png)

![image](https://user-images.githubusercontent.com/11358728/118374353-00e82a80-b592-11eb-9bad-53668ff6d831.png)
